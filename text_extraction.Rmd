---
title: "R Notebook"
output: html_notebook
---


```{r}

options(java.parameters = c("-XX:+UseConcMarkSweepGC", "-Xmx8192m")) #- run if outofmemory error while text extracting
gc()
library(pdftools)
library(tidyverse)
library(magrittr)
library(stringi)
library(cld2)
library(tabulizer)

```

```{r}
compiled_gic <- read.csv("joined_df.csv")
manual_gic_1 <- read.csv("eng_orgs_joined_man_page.csv")
manual_gic_2 <- read.csv("orlist_with_gri_manual.csv")
names(manual_gic_1)[14] <- "page"
```

```{r}
manual_gic_2 %<>%
  filter(!is.na(page), !page=="", !page=="-", !page=="0") %>% 
  mutate(page=str_replace_all(page, "\\.", ","),
                         page=str_replace_all(page, " ", ""),
                         page=str_replace_all(page, ",", " "),
                         page=lapply(strsplit(page, " "),as.numeric),
                         gcode=as.integer(str_sub(gcode2, 1,3)))

manual_gic_2 %<>% unnest(page)

manual_gic_2 %>% distinct(fullpath)
  
```

```{r}
columns_dry <- c("orig_id","organization","fullpath","gcode","page")
columns_2group <- c("orig_id","organization","country","pub_year","fullpath","gcode")
columns_full <- c("orig_id","organization","fullpath","gcode","gcode2","real_pdf_page")
```

```{r}

## first variant of text extraction

y<-compiled_gic
y<-manual_gic
y %<>% mutate(text="")

for (i in 1:nrow(y)){ #very poor design, uncomment pdf_text line if you need to run it
  
  out <- tryCatch(
    expr = {
      #x<-pdf_text(y$fullpath[i]) %>%  str_split("\n")
      y$text[i]<-x[y$real_pdf_page[i]]
    },
    error = function(e){ 
  
      return(NULL)
    }
  )
  
}
```

```{r}

qq5 <- manual_gic_1 %>%
  select(all_of(columns_dry)) %>% 
  distinct(.keep_all = T) %>% 
  filter(!is.na(real_pdf_page), real_pdf_page!="0") %>% 
  group_by(orig_id,organization,fullpath,gcode) %>%
  summarise(pdf_page = c(cur_data()), .groups = "rowwise")

qq5[192:195,] %<>% mutate(fullpath="reports/kernel/2019/kernel_fy2019_annual_report.pdf") # due to manual processing of pages didn't have the right path

qq6 <- manual_gic_2 %>%
  select(all_of(columns_dry)) %>% 
  distinct(.keep_all = T) %>% 
  filter(!is.na(page), page!="0") %>% 
  group_by(orig_id,organization,fullpath,gcode) %>%
  summarise(pdf_page = c(cur_data()), .groups = "rowwise")

qq7 <- full_join(qq5,qq6)
#qq7 %<>% unnest(pdf_page)
#qq7 %>% group_by(gcode) %>% count(sort = T)


```

```{r}



```



```{r}
## second variant of extracting text. neat and quick

qq7 %<>% mutate(text="")

#for (i in 1:nrow(qq7)) {
#  qq7$text[i] <- extract_text(qq7$fullpath[i],unlist(as.vector(qq7$pdf_page[i])))
#}

qq7 %<>% mutate(text=list(extract_text(fullpath, unlist(as.vector(pdf_page))))) # text extraction

qq7 %<>% mutate(lang=list(detect_language(text)))

#qq8 <- qq7 %>% unnest()
#qq9 <-qq8 %>% nest(cols = c(pdf_page, text, lang))
#vignette("nest")

#write.csv(qq8, "orlist_coges_pages_text_unnested.csv")
saveRDS(qq8,"orlist_coges_pages_text_unnested.rds")

```

```{r}

qq10 <- qq8 %>% group_by(fullpath,gcode) %>% summarise(pages=list(pdf_page))

qq8 %>% filter(!lang=="en")

```


```{r}

## draft for text extracting

qq <- manual_gic
qq %<>% mutate(text="")
j<-10
xx1<-pdf_text(qq$fullpath[j])
xx2<-extract_text(qq7$fullpath[j], unlist(as.vector(qq7$pdf_page[j])))


temp<-unlist(as.vector(qq3$pdf_page[j]))
unlist(temp)
qq2 <- qq %>% select(orig_id,organization,fullpath,gcode,real_pdf_page) %>% nest_by(orig_id,organization,fullpath,gcode)

qq2[[3]][[5]]$real_pdf_page


temp <- qq %>% select(orig_id,organization,fullpath,gcode,real_pdf_page) %>% distinct(.keep_all = T) #%>% 
  filter(!is.na(real_pdf_page), real_pdf_page!="0")



qq3 %<>% mutate(text=list(c()))
qq3[151:202,] %<>% mutate(text=list(extract_text(fullpath, unlist(as.vector(pdf_page)))))





rlang::last_error()
```


```{r}
```


```{r}
z<- y %>% mutate(text=as.character(text))
z %<>% unnest(text)
```


```{r}
selected_columns <- c("X", "Organization", "Country_Organization_Account", "Publication_Year", "fullpath", "pdf_contents_page", "gcode", "gcode2", "name", "value", "text")
b <- z[selected_columns] 

rename_col <-c("orig_id", "organization", "country", "pub_year", "fullpath", "pdf_contents_page", "gcode", "gcode2", "orig_code_str", "page_num", "text")
names(b) <-rename_col

b <-b[!b$text %in% c("NULL", ""),]

b %<>% mutate(lang=detect_language(text))

eng_orgs <- b %>% group_by(orig_id, organization, lang) %>% summarize(.groups = "keep") %>% filter(lang=="en")

eng_orgs_joined <- left_join(eng_orgs, b, by=c("orig_id", "lang", "organization"), keep=F)

gri_list_df %>% select(X, Report_PDF_Address) %>% group_by(X) %>% glimpse(10)

#eng_orgs_joined %>% left_join()

eng_orgs_joined %<>% mutate(corr_page="")
eng_orgs_joined %<>% select(-text)
write.csv(b, "companies_codes_text.csv")

write.csv(eng_orgs_joined, "eng_orgs_joined3.csv")

eoj_complist <- eng_orgs_joined %>% group_by(orig_id,organization) %>% count()

write.csv(eoj_complist, "orlist2.csv")

b[b$country %in% c("United Kingdom of Great Britain and Northern Ireland", "United States of America", "Denmark", "Sweden"),] %>% head(30)

```


```{r}

eoj_new <- eng_orgs_joined %>% select(orig_id, organization, country, pub_year, fullpath, pdf_contents_page) %>% distinct()

# eoj_new_gri <- eoj_new[rep(seq_len(nrow(eoj_new)), 59),] %>% arrange(orig_id)

my_codes <- c("401", "401-1", "401-2", "401-3", "402", "402-1", "403", "403-1", "403-2", "403-3", "403-4", "403-5", "403-6", "403-7", "403-8", "403-9", "403-10", "404", "404-1", "404-2", "404-3", "405", "405-1", "405-2", "406", "406-1", "407", "407-1", "408", "408-1", "409", "409-1", "410", "410-1", "411", "411-1", "412", "412-1", "412-2", "412-3", "413", "413-1", "413-2", "414", "414-1", "414-2", "415", "415-1", "416", "416-1", "416-2", "417", "417-1", "417-2", "417-3", "418", "418-1", "419", "419-1")

eoj_new_gri <- eoj_new %>% slice(25:175) %>% mutate(gcode2=list(my_codes)) %>% filter(orig_id!="2606")

eoj_new_gri %<>% unnest(gcode2)

write.csv(eoj_new_gri, "orlist_with_gri.csv")

eoj_new %<>% slice(25:175) %>% filter(orig_id!="2606")
write.csv(eoj_new, "orlist3.csv")

```

